{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6arBSn-QBDA",
        "outputId": "ab662d3a-1811-4ff8-ed3d-9ecb0d2b999a"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mR3l-f70YkID",
        "outputId": "dc66487e-0623-4713-c7ae-8922d22cae96"
      },
      "outputs": [],
      "source": [
        "!pip install face_recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOr6nWmUYZjd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import face_recognition\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "class VideoDataset(Dataset):\n",
        "    def __init__(self, video_names, labels, sequence_length=20, transform=None):\n",
        "        \"\"\"\n",
        "        Initializes the VideoDataset.\n",
        "\n",
        "        Args:\n",
        "        - video_names (list): List of video file names.\n",
        "        - labels (pandas.DataFrame): DataFrame containing video labels.\n",
        "        - sequence_length (int): Length of the sequence to be extracted.\n",
        "        - transform (callable): Optional transform to be applied on a sample.\n",
        "        \"\"\"\n",
        "        self.video_names = video_names\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        self.sequence_length = sequence_length\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the length of the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.video_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      \"\"\"\n",
        "      Gets a sample from the dataset.\n",
        "\n",
        "      Args:\n",
        "      - idx (int): Index of the sample to retrieve.\n",
        "\n",
        "      Returns:\n",
        "      - frames (torch.Tensor): Extracted frames from the video.\n",
        "      - label (int): Label of the video (0 for REAL, 1 for FAKE).\n",
        "      \"\"\"\n",
        "      video_path = self.video_names[idx]\n",
        "      # print(\"Processing video:\", video_path)  # Add this line for debugging\n",
        "      frames = []\n",
        "\n",
        "      # Load frames from video\n",
        "      for i, frame in enumerate(self.frame_extract(video_path)):\n",
        "          frames.append(self.transform(frame))\n",
        "          if len(frames) == self.sequence_length:\n",
        "              break\n",
        "\n",
        "      # Pad frames to ensure consistent sequence length\n",
        "      while len(frames) < self.sequence_length:\n",
        "          if len(frames) > 0:\n",
        "              frames.append(torch.zeros_like(frames[0]))  # Pad with zeros\n",
        "          else:\n",
        "              # If frames is empty, just add a zero tensor of the appropriate shape\n",
        "              frames.append(torch.zeros(3, 256, 256))  # Modify dimensions as needed\n",
        "\n",
        "      frames = torch.stack(frames)\n",
        "      frames = frames[:self.sequence_length]\n",
        "\n",
        "      # Get label\n",
        "      temp_video = video_path.split('/')[-1]\n",
        "      label = self.labels.loc[self.labels[\"file\"] == temp_video, \"label\"].values[0]\n",
        "      label = 0 if label == 'REAL' else 1\n",
        "\n",
        "      return frames, label\n",
        "\n",
        "\n",
        "    def frame_extract(self, path):\n",
        "        \"\"\"\n",
        "        Extracts frames from the video at the given path.\n",
        "\n",
        "        Args:\n",
        "        - path (str): Path to the video file.\n",
        "\n",
        "        Yields:\n",
        "        - image (numpy.ndarray): Extracted frame from the video.\n",
        "        \"\"\"\n",
        "        vidObj = cv2.VideoCapture(path)\n",
        "        success = 1\n",
        "\n",
        "        while success:\n",
        "            success, image = vidObj.read()\n",
        "            if success:\n",
        "                yield image\n",
        "\n",
        "def im_plot(tensor):\n",
        "    \"\"\"\n",
        "    Plots the image represented by the given tensor.\n",
        "\n",
        "    Args:\n",
        "    - tensor (torch.Tensor): Tensor representing the image.\n",
        "    \"\"\"\n",
        "    image = tensor.cpu().numpy().transpose(1, 2, 0)\n",
        "    b, g, r = cv2.split(image)\n",
        "    image = cv2.merge((r, g, b))\n",
        "    image = image * [0.22803, 0.22145, 0.216989] + [0.43216, 0.394666, 0.37645]\n",
        "    image = image * 255.0\n",
        "    plt.imshow(image.astype(int))\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyy2fggYYvHr",
        "outputId": "8ebfde5a-c62e-4af3-a279-92a4ed44cb5b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "path_csv = \"/content/drive/MyDrive/metadata files/metadata-global.csv\"\n",
        "read_csv = pd.read_csv(path_csv)\n",
        "print(read_csv.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvISKKq76NH5"
      },
      "outputs": [],
      "source": [
        "#count the number of fake and real videos\n",
        "def number_of_real_and_fake_videos(data_list):\n",
        "  header_list = [\"file\",\"label\", \"split\"]\n",
        "  lab = pd.read_csv('/content/drive/MyDrive/metadata files/metadata-global.csv',names=header_list)\n",
        "  fake = 0\n",
        "  real = 0\n",
        "  for i in data_list:\n",
        "    temp_video = i.split('/')[-1]\n",
        "    label = lab.iloc[(labels.loc[labels[\"file\"] == temp_video].index.values[0]),1]\n",
        "    if(label == 'FAKE'):\n",
        "      fake+=1\n",
        "    if(label == 'REAL'):\n",
        "      real+=1\n",
        "  return real,fake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VI5vapokkbN"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "# Get paths of train and test videos\n",
        "train_videos = glob.glob('/content/drive/MyDrive/preprocessed dataset/train/*.mp4')\n",
        "test_videos = glob.glob('/content/drive/MyDrive/preprocessed dataset/test/*.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ojTqGF9lRQW",
        "outputId": "ef9c9b8d-d923-4d16-a306-108462c77d5c"
      },
      "outputs": [],
      "source": [
        "print(\"train : \" , len(train_videos))\n",
        "print(\"test : \" , len(test_videos))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMmGZ4GyusQC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the header list for the DataFrame\n",
        "header_list = [\"file\", \"label\", \"split\"]\n",
        "\n",
        "# Read the metadata CSV file into a DataFrame\n",
        "labels = pd.read_csv('/content/drive/MyDrive/metadata files/metadata-global.csv', names=header_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "qiQOHCY815VL",
        "outputId": "58ff80d7-67b6-442e-a749-318b2171b1ee"
      },
      "outputs": [],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhSROTN_lSYs",
        "outputId": "0c005b87-0fd3-48ee-8e54-a54c4493c558"
      },
      "outputs": [],
      "source": [
        "print(\"TRAIN: \", \"Real:\",number_of_real_and_fake_videos(train_videos)[0],\" Fake:\",number_of_real_and_fake_videos(train_videos)[1])\n",
        "print(\"TEST: \", \"Real:\",number_of_real_and_fake_videos(test_videos)[0],\" Fake:\",number_of_real_and_fake_videos(test_videos)[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKntMD4g0JL_"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define image size and normalization parameters\n",
        "im_size = 256\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "# Define transforms for training data\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((im_size, im_size)),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "# Define transforms for test/validation data\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((im_size, im_size)),\n",
        "    transforms.Normalize(mean, std)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hBNaK7n3z0-"
      },
      "outputs": [],
      "source": [
        "# Create VideoDataset instances for training and testing data\n",
        "train_data = VideoDataset(train_videos, labels, sequence_length=20, transform=train_transforms)\n",
        "test_data = VideoDataset(test_videos, labels, sequence_length=20, transform=test_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgUQ0Pdm4Jxg"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Create DataLoader instances for training and validation data\n",
        "train_loader = DataLoader(train_data, batch_size=2, shuffle=True, num_workers=4)\n",
        "valid_loader = DataLoader(test_data, batch_size=2, shuffle=True, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8azX8dG5PK9"
      },
      "outputs": [],
      "source": [
        "#Model with feature visualization\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, num_classes,latent_dim= 2048, lstm_layers=1 , hidden_dim = 2048, bidirectional = False):\n",
        "        super(Model, self).__init__()\n",
        "        model = models.resnext50_32x4d(pretrained = True) #Residual Network CNN\n",
        "        self.model = nn.Sequential(*list(model.children())[:-2])\n",
        "        self.lstm = nn.LSTM(latent_dim,hidden_dim, lstm_layers,  bidirectional)\n",
        "        self.relu = nn.LeakyReLU()\n",
        "        self.dp = nn.Dropout(0.4)\n",
        "        self.linear1 = nn.Linear(2048,num_classes)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "    def forward(self, x):\n",
        "        batch_size,seq_length, c, h, w = x.shape\n",
        "        x = x.view(batch_size * seq_length, c, h, w)\n",
        "        fmap = self.model(x)\n",
        "        x = self.avgpool(fmap)\n",
        "        x = x.view(batch_size,seq_length,2048)\n",
        "        x_lstm,_ = self.lstm(x,None)\n",
        "        return fmap,self.dp(self.linear1(torch.mean(x_lstm,dim = 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1ATbQmzgsUE",
        "outputId": "25f9ad9c-e749-490e-f7c4-9085371ffe3c"
      },
      "outputs": [],
      "source": [
        "model = Model(2).cuda()\n",
        "a,b = model(torch.from_numpy(np.empty((1,20,3,256,256))).type(torch.cuda.FloatTensor))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCGC7ZC2gsqm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "\n",
        "def train_epoch(epoch, num_epochs, data_loader, model, criterion, optimizer):\n",
        "    model.train()\n",
        "    losses = AverageMeter()\n",
        "    accuracies = AverageMeter()\n",
        "    start_time = time.time()  # Record the start time of the epoch\n",
        "    for i, (inputs, targets) in enumerate(data_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            targets = targets.type(torch.cuda.LongTensor)\n",
        "            inputs = inputs.cuda()\n",
        "        _, outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets.type(torch.cuda.LongTensor))\n",
        "        acc = calculate_accuracy(outputs, targets.type(torch.cuda.LongTensor))\n",
        "        losses.update(loss.item(), inputs.size(0))\n",
        "        accuracies.update(acc, inputs.size(0))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate remaining time\n",
        "        elapsed_time = time.time() - start_time\n",
        "        average_time_per_epoch = elapsed_time / (epoch * len(data_loader) + i + 1)\n",
        "        remaining_epochs = num_epochs - epoch\n",
        "        remaining_batches = len(data_loader) - i - 1\n",
        "        remaining_time = remaining_epochs * remaining_batches * average_time_per_epoch\n",
        "\n",
        "        sys.stdout.write(\n",
        "            \"\\r[Epoch %d/%d] [Batch %d/%d] [Loss: %f, Acc: %.2f%%] [ETA: %s]\"\n",
        "            % (\n",
        "                epoch,\n",
        "                num_epochs,\n",
        "                i + 1,\n",
        "                len(data_loader),\n",
        "                losses.avg,\n",
        "                accuracies.avg,\n",
        "                format_time(remaining_time)\n",
        "            )\n",
        "        )\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    torch.save(model.state_dict(), '/content/deepfakenet.pt')\n",
        "    return losses.avg, accuracies.avg\n",
        "\n",
        "def format_time(seconds):\n",
        "    minutes, seconds = divmod(seconds, 60)\n",
        "    hours, minutes = divmod(minutes, 60)\n",
        "    return \"{:02}:{:02}:{:02}\".format(int(hours), int(minutes), int(seconds))\n",
        "\n",
        "def test(epoch,model, data_loader ,criterion):\n",
        "    print('Testing')\n",
        "    model.eval()\n",
        "    losses = AverageMeter()\n",
        "    accuracies = AverageMeter()\n",
        "    pred = []\n",
        "    true = []\n",
        "    count = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, targets) in enumerate(data_loader):\n",
        "            if torch.cuda.is_available():\n",
        "                targets = targets.cuda().type(torch.cuda.FloatTensor)\n",
        "                inputs = inputs.cuda()\n",
        "            _,outputs = model(inputs)\n",
        "            loss = torch.mean(criterion(outputs, targets.type(torch.cuda.LongTensor)))\n",
        "            acc = calculate_accuracy(outputs,targets.type(torch.cuda.LongTensor))\n",
        "            _,p = torch.max(outputs,1)\n",
        "            true += (targets.type(torch.cuda.LongTensor)).detach().cpu().numpy().reshape(len(targets)).tolist()\n",
        "            pred += p.detach().cpu().numpy().reshape(len(p)).tolist()\n",
        "            losses.update(loss.item(), inputs.size(0))\n",
        "            accuracies.update(acc, inputs.size(0))\n",
        "            sys.stdout.write(\n",
        "                    \"\\r[Batch %d / %d]  [Loss: %f, Acc: %.2f%%]\"\n",
        "                    % (\n",
        "                        i,\n",
        "                        len(data_loader),\n",
        "                        losses.avg,\n",
        "                        accuracies.avg\n",
        "                        )\n",
        "                    )\n",
        "        print('\\nAccuracy {}'.format(accuracies.avg))\n",
        "    return true,pred,losses.avg,accuracies.avg\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "def calculate_accuracy(outputs, targets):\n",
        "    batch_size = targets.size(0)\n",
        "\n",
        "    _, pred = outputs.topk(1, 1, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(targets.view(1, -1))\n",
        "    n_correct_elems = correct.float().sum().item()\n",
        "    return 100* n_correct_elems / batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErJB5ljhgxyQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "#learning rate\n",
        "lr = 1e-5 #0.001\n",
        "#number of epochs\n",
        "num_epochs = 50\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr= lr,weight_decay = 1e-5)\n",
        "\n",
        "#class_weights = torch.from_numpy(np.asarray([1,15])).type(torch.FloatTensor).cuda()\n",
        "#criterion = nn.CrossEntropyLoss(weight = class_weights).cuda()\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "train_loss_avg =[]\n",
        "train_accuracy = []\n",
        "test_loss_avg = []\n",
        "test_accuracy = []\n",
        "for epoch in range(1,num_epochs+1):\n",
        "    l, acc = train_epoch(epoch,num_epochs,train_loader,model,criterion,optimizer)\n",
        "    train_loss_avg.append(l)\n",
        "    train_accuracy.append(acc)\n",
        "    true,pred,tl,t_acc = test(epoch,model,valid_loader,criterion)\n",
        "    test_loss_avg.append(tl)\n",
        "    test_accuracy.append(t_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkD-uSG5IGxb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQT-wrM5VB9C"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
